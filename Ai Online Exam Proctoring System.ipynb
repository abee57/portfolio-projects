{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71121f5b-8ef3-4ba0-b9a8-67ca1523ca9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Advanced ExamProctor v2.5 - TOTAL VIOLATION COUNTING!\n",
      "âœ… Proctor v2.5 READY! (Total: 2=Warning, 4=Lockout)\n",
      "ğŸ”Š Audio ON (20dB threshold)\n",
      "ğŸ¥ LIVE! q=quit, s=summary\n",
      "ğŸ“± Test: Any violation 2x=âš ï¸WARNING, 4x=ğŸ”’LOCKOUT (TOTAL COUNT)\n",
      "ğŸš¨ [2025-12-26T01:47:55] LookingRight: 15.0 (TOTAL: 1/4)\n",
      "ğŸ“Š TOTAL Violations: 1/4\n",
      "ğŸ“Š TOTAL Violations: 1/4\n",
      "ğŸ“Š TOTAL Violations: 1/4\n",
      "ğŸ“Š TOTAL Violations: 1/4\n",
      "ğŸ“Š TOTAL Violations: 1/4\n",
      "ğŸ“Š TOTAL Violations: 1/4\n",
      "ğŸ“Š TOTAL Violations: 1/4\n",
      "ğŸ“Š TOTAL Violations: 1/4\n",
      "ğŸ“Š TOTAL Violations: 1/4\n",
      "ğŸš¨ [2025-12-26T01:47:58] LookingRight: 15.3 (TOTAL: 2/4)\n",
      "ğŸ“Š TOTAL Violations: 2/4\n",
      "ğŸ”” âš ï¸ WARNING: 2 violations detected\n",
      "ğŸš¨ [2025-12-26T01:47:58] LookingLeft: -15.1 (TOTAL: 3/4)\n",
      "ğŸ“Š TOTAL Violations: 3/4\n",
      "ğŸ”” âš ï¸ WARNING: 3 violations detected\n",
      "ğŸ“Š TOTAL Violations: 3/4\n",
      "ğŸ”” âš ï¸ WARNING: 3 violations detected\n",
      "ğŸ“Š TOTAL Violations: 3/4\n",
      "ğŸ”” âš ï¸ WARNING: 3 violations detected\n",
      "ğŸ“Š TOTAL Violations: 3/4\n",
      "ğŸ”” âš ï¸ WARNING: 3 violations detected\n",
      "ğŸ“Š TOTAL Violations: 3/4\n",
      "ğŸ”” âš ï¸ WARNING: 3 violations detected\n",
      "ğŸ“Š TOTAL Violations: 3/4\n",
      "ğŸ”” âš ï¸ WARNING: 3 violations detected\n",
      "ğŸ“Š TOTAL Violations: 3/4\n",
      "ğŸ”” âš ï¸ WARNING: 3 violations detected\n",
      "ğŸ“Š TOTAL Violations: 3/4\n",
      "ğŸ”” âš ï¸ WARNING: 3 violations detected\n",
      "ğŸš¨ [2025-12-26T01:48:06] LookingRight: 24.9 (TOTAL: 4/4)\n",
      "ğŸ“Š TOTAL Violations: 4/4\n",
      "ğŸ”” âš ï¸ WARNING: 4 violations detected\n",
      "ğŸ”” ğŸ”’ EXAM CANCELLED: Multiple violations (4+ violations)\n",
      "ğŸš¨ [2025-12-26T01:48:06] EXAM_LOCKED: Multiple violations (TOTAL: 5/4)\n",
      "\n",
      "ğŸ“Š SUMMARY SAVED:\n",
      "{\n",
      "  \"session_id\": \"exam_1766713673\",\n",
      "  \"duration_min\": 0.3,\n",
      "  \"total_violations\": 5,\n",
      "  \"total_alerts\": 1,\n",
      "  \"suspicion_score\": 1.0,\n",
      "  \"exam_locked\": true,\n",
      "  \"violations\": {},\n",
      "  \"avg_fps\": 42.029953466513525,\n",
      "  \"recommendation\": \"FAIL\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import sounddevice as sd\n",
    "import queue\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import deque, Counter\n",
    "import winsound  # Windows beep sound\n",
    "\n",
    "print(\"ğŸš€ Advanced ExamProctor v2.5 - TOTAL VIOLATION COUNTING!\")\n",
    "\n",
    "CONFIG = {\n",
    "    \"blink_ear_thresh\": 0.25,\n",
    "    \"audio_thresh_db\": -20.0,  # ğŸ”Š Changed to 20dB as requested\n",
    "    \"mouth_mar_thresh\": 0.55,\n",
    "    \"yaw_thresh\": 15.0,\n",
    "    \"pitch_thresh\": 12.0,\n",
    "    \"occlusion_frames\": 15,\n",
    "    \"mobile_size_min\": 3000,\n",
    "    \"mobile_size_max\": 25000,\n",
    "    \"shoulder_move_thresh\": 25,\n",
    "    \"total_violations_warning\": 2,   # âš ï¸ WARNING after 2 TOTAL violations\n",
    "    \"total_violations_lockout\": 4    # ğŸ”’ LOCKOUT after 4 TOTAL violations\n",
    "}\n",
    "\n",
    "class AdvancedExamProctor:\n",
    "    def __init__(self, cam_idx=0, log_csv=\"proctor_log.csv\"):\n",
    "        self.log_csv_path = log_csv\n",
    "        self.cam_idx = cam_idx\n",
    "        self.session_start = time.time()\n",
    "        self.json_alert_id = 0\n",
    "        self.last_beep_time = 0\n",
    "        self.exam_locked = False\n",
    "        self.lockout_time = 0\n",
    "        \n",
    "        # ğŸ”¥ NEW: Total violation counter (ALL types combined)\n",
    "        self.total_violations = 0\n",
    "        \n",
    "        # MediaPipe\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.face_mesh = self.mp_face_mesh.FaceMesh(\n",
    "            static_image_mode=False, max_num_faces=4, refine_landmarks=True,\n",
    "            min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "        self.mp_draw = mp.solutions.drawing_utils\n",
    "        self.drawing_spec = self.mp_draw.DrawingSpec(thickness=1, circle_radius=1)\n",
    "        \n",
    "        # State\n",
    "        self.alerts_json = []\n",
    "        self.suspicion_score = 0.0\n",
    "        self.violation_history = Counter()\n",
    "        self.blink_history = deque(maxlen=300)\n",
    "        self.occlusion_count = 0\n",
    "        self._audio_rms_db = -120.0\n",
    "        self._audio_queue = queue.Queue()\n",
    "        self._audio_running = False\n",
    "        self.violation_cooldowns = {}\n",
    "        self.fps_history = deque(maxlen=60)\n",
    "        self.shoulder_positions = deque(maxlen=10)\n",
    "        \n",
    "        # ğŸ”¥ Warning system\n",
    "        self.warning_active = False\n",
    "        self.warning_message = \"\"\n",
    "        self.warning_start_time = 0\n",
    "        \n",
    "        self.cap = cv2.VideoCapture(cam_idx)\n",
    "        self._ensure_log_exists()\n",
    "        print(\"âœ… Proctor v2.5 READY! (Total: 2=Warning, 4=Lockout)\")\n",
    "\n",
    "    def _ensure_log_exists(self):\n",
    "        if not os.path.exists(self.log_csv_path):\n",
    "            with open(self.log_csv_path, 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"timestamp\", \"violation_type\", \"value\", \"details\"])\n",
    "\n",
    "    def log_event(self, vtype, value=\"\", details=\"\"):\n",
    "        now = time.time()\n",
    "        if now - self.violation_cooldowns.get(vtype, 0) < 3.0: return\n",
    "        self.violation_cooldowns[vtype] = now\n",
    "        \n",
    "        # ğŸ”¥ INCREMENT TOTAL VIOLATION COUNT\n",
    "        self.total_violations += 1\n",
    "        \n",
    "        ts = datetime.utcnow().isoformat(timespec='seconds') + 'Z'\n",
    "        with open(self.log_csv_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([ts, vtype, value, details])\n",
    "        print(f\"ğŸš¨ [{ts[:19]}] {vtype}: {value} (TOTAL: {self.total_violations}/4)\")\n",
    "\n",
    "    def check_total_violations(self):\n",
    "        \"\"\"ğŸ”¥ NEW: Total violation counting (ALL types)\"\"\"\n",
    "        print(f\"ğŸ“Š TOTAL Violations: {self.total_violations}/4\")  # Debug\n",
    "        \n",
    "        # âš ï¸ WARNING after 2 TOTAL violations\n",
    "        if self.total_violations >= CONFIG[\"total_violations_warning\"]:\n",
    "            self.show_on_screen_warning(f\"âš ï¸ WARNING: {self.total_violations} violations detected\")\n",
    "            self.beep_alert(1200, 500)\n",
    "            \n",
    "            # ğŸ”’ LOCKOUT after 4 TOTAL violations\n",
    "            if self.total_violations >= CONFIG[\"total_violations_lockout\"]:\n",
    "                self.lock_exam(\"Multiple violations\")\n",
    "                return True\n",
    "                \n",
    "        return False\n",
    "\n",
    "    def beep_alert(self, frequency=800, duration=200):\n",
    "        now = time.time()\n",
    "        if now - self.last_beep_time > 1.0:\n",
    "            try:\n",
    "                winsound.Beep(frequency, duration)\n",
    "                self.last_beep_time = now\n",
    "            except:\n",
    "                print(\"\\a\")\n",
    "\n",
    "    def show_on_screen_warning(self, message):\n",
    "        self.warning_active = True\n",
    "        self.warning_message = message\n",
    "        self.warning_start_time = time.time()\n",
    "        print(f\"ğŸ”” {message}\")\n",
    "\n",
    "    def lock_exam(self, reason):\n",
    "        if self.exam_locked: return\n",
    "        self.exam_locked = True\n",
    "        self.lockout_time = time.time()\n",
    "        self.show_on_screen_warning(f\"ğŸ”’ EXAM CANCELLED: {reason} (4+ violations)\")\n",
    "        self.log_event(\"EXAM_LOCKED\", reason, f\"Total {self.total_violations} violations\")\n",
    "        self.create_json_alert(\"EXAM_LOCKED\", \"CRITICAL\", 1.0, {\"reason\": reason, \"total_violations\": self.total_violations})\n",
    "\n",
    "    def draw_warning_overlay(self, frame, h, w):\n",
    "        if self.warning_active:\n",
    "            alpha = 0.3\n",
    "            overlay = frame.copy()\n",
    "            \n",
    "            if self.exam_locked:\n",
    "                cv2.rectangle(overlay, (0, 0), (w, h), (0, 0, 139), -1)\n",
    "                cv2.putText(overlay, \"ğŸ”’ EXAM CANCELLED\", (w//2-200, h//2-50), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 4)\n",
    "                cv2.putText(overlay, f\"Violations: {self.total_violations}\", (w//2-150, h//2+20), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
    "                cv2.putText(overlay, \"Restart app to continue\", (w//2-180, h//2+70), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "            else:\n",
    "                cv2.rectangle(overlay, (0, 50), (w, 150), (0, 165, 255), -1)\n",
    "                cv2.putText(overlay, self.warning_message, (20, 110), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "                cv2.rectangle(overlay, (20, 120), (w-20, 140), (255, 255, 0), 3)\n",
    "            \n",
    "            cv2.addWeighted(overlay, alpha, frame, 1-alpha, 0, frame)\n",
    "            \n",
    "            if not self.exam_locked and time.time() - self.warning_start_time > 5.0:\n",
    "                self.warning_active = False\n",
    "\n",
    "    def get_current_time(self):\n",
    "        now = datetime.now()\n",
    "        return now.strftime(\"%H:%M:%S %d/%m/%Y\")\n",
    "\n",
    "    def rms_to_db(self, rms):\n",
    "        return -120.0 if rms <= 1e-10 else 20.0 * math.log10(rms)\n",
    "\n",
    "    def _audio_callback(self, indata, frames, time_info, status):\n",
    "        if status: print(f\"Audio: {status}\")\n",
    "        try:\n",
    "            mono = np.mean(indata, axis=1)\n",
    "            rms = np.sqrt(np.mean(mono**2))\n",
    "            db = self.rms_to_db(rms)\n",
    "            self._audio_queue.put_nowait(db)\n",
    "        except: pass\n",
    "\n",
    "    def start_audio(self):\n",
    "        try:\n",
    "            self._audio_stream = sd.InputStream(samplerate=16000, blocksize=1024, \n",
    "                                              channels=1, callback=self._audio_callback)\n",
    "            self._audio_stream.start()\n",
    "            self._audio_running = True\n",
    "            print(\"ğŸ”Š Audio ON (20dB threshold)\")\n",
    "        except Exception as e:\n",
    "            print(f\"Audio optional: {e}\")\n",
    "\n",
    "    def extract_landmark_points(self, landmarks, indices, img_shape):\n",
    "        h, w = img_shape[:2]\n",
    "        points = []\n",
    "        for idx in indices:\n",
    "            lm = landmarks[idx]\n",
    "            x, y = int(lm.x * w), int(lm.y * h)\n",
    "            points.append(np.array([x, y], dtype=np.float32))\n",
    "        return np.array(points)\n",
    "\n",
    "    def eye_aspect_ratio(self, eye_pts):\n",
    "        A = np.linalg.norm(eye_pts[1] - eye_pts[5])\n",
    "        B = np.linalg.norm(eye_pts[2] - eye_pts[4])\n",
    "        C = np.linalg.norm(eye_pts[0] - eye_pts[3])\n",
    "        return (A + B) / (2.0 * C)\n",
    "\n",
    "    def detect_blink(self, landmarks, img_shape):\n",
    "        left_eye_indices = [36, 37, 38, 39, 40, 41]\n",
    "        right_eye_indices = [42, 43, 44, 45, 46, 47]\n",
    "        \n",
    "        left_eye_pts = self.extract_landmark_points(landmarks, left_eye_indices, img_shape)\n",
    "        right_eye_pts = self.extract_landmark_points(landmarks, right_eye_indices, img_shape)\n",
    "        \n",
    "        left_ear = self.eye_aspect_ratio(left_eye_pts)\n",
    "        right_ear = self.eye_aspect_ratio(right_eye_pts)\n",
    "        ear = (left_ear + right_ear) / 2.0\n",
    "        \n",
    "        self.blink_history.append(ear)\n",
    "        return ear < CONFIG[\"blink_ear_thresh\"], left_ear, right_ear\n",
    "\n",
    "    def draw_eye_landmarks(self, frame, landmarks, h, w):\n",
    "        \"\"\"ğŸ”¥ SMALLER RED DOTS - Only key eye points\"\"\"\n",
    "        # Only draw 6 key points per eye (much smaller coverage)\n",
    "        left_eye_key = [36, 39, 42]  # Top, center, bottom of left eye\n",
    "        right_eye_key = [33, 45, 46]  # Top, center, bottom of right eye\n",
    "        \n",
    "        # Left eye - smaller dots\n",
    "        for idx in left_eye_key:\n",
    "            x, y = int(landmarks[idx].x * w), int(landmarks[idx].y * h)\n",
    "            eye_color = (0, 0, 255) if landmarks[idx].y > 0.25 else (0, 255, 0)\n",
    "            cv2.circle(frame, (x, y), 1, eye_color, -1)  # Radius 1 (much smaller!)\n",
    "        \n",
    "        # Right eye - smaller dots\n",
    "        for idx in right_eye_key:\n",
    "            x, y = int(landmarks[idx].x * w), int(landmarks[idx].y * h)\n",
    "            eye_color = (0, 0, 255) if landmarks[idx].y > 0.25 else (0, 255, 0)\n",
    "            cv2.circle(frame, (x, y), 1, eye_color, -1)  # Radius 1\n",
    "\n",
    "    def detect_mobile_phone(self, frame, gray):\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if CONFIG[\"mobile_size_min\"] < area < CONFIG[\"mobile_size_max\"]:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                aspect_ratio = w / float(h)\n",
    "                \n",
    "                if 1.8 < aspect_ratio < 3.0 or 0.33 < aspect_ratio < 0.55:\n",
    "                    peri = cv2.arcLength(contour, True)\n",
    "                    approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "                    \n",
    "                    if len(approx) >= 4:\n",
    "                        roi = frame[y:y+h, x:x+w]\n",
    "                        if roi.size > 0:\n",
    "                            mean_color = np.mean(roi)\n",
    "                            if 50 < mean_color < 180:\n",
    "                                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 3)\n",
    "                                cv2.putText(frame, \"ğŸ“± MOBILE!\", (x, y-10), \n",
    "                                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                                return True\n",
    "        return False\n",
    "\n",
    "    def detect_shoulder_movement(self, landmarks, img_shape):\n",
    "        h, w = img_shape[:2]\n",
    "        left_shoulder_idx = 10\n",
    "        right_shoulder_idx = 390\n",
    "        \n",
    "        try:\n",
    "            left_pos = np.array([landmarks[left_shoulder_idx].x * w, landmarks[left_shoulder_idx].y * h])\n",
    "            right_pos = np.array([landmarks[right_shoulder_idx].x * w, landmarks[right_shoulder_idx].y * h])\n",
    "            shoulder_center = (left_pos + right_pos) / 2\n",
    "            \n",
    "            if len(self.shoulder_positions) > 0:\n",
    "                prev_center = self.shoulder_positions[-1]\n",
    "                movement = np.linalg.norm(shoulder_center - prev_center)\n",
    "                if movement > CONFIG[\"shoulder_move_thresh\"]:\n",
    "                    self.shoulder_positions.append(shoulder_center)\n",
    "                    return True, movement\n",
    "            \n",
    "            self.shoulder_positions.append(shoulder_center)\n",
    "        except:\n",
    "            pass\n",
    "        return False, 0\n",
    "\n",
    "    def estimate_head_pose(self, img_shape, landmarks_2d):\n",
    "        model_points = np.array([\n",
    "            [0.0, 0.0, 0.0], [0.0, -63.6, -12.5], [-43.3, 32.7, -26.0],\n",
    "            [43.3, 32.7, -26.0], [-28.9, -28.9, -24.1], [28.9, -28.9, -24.1]\n",
    "        ], dtype=\"double\")\n",
    "        \n",
    "        try:\n",
    "            image_points = np.array(list(landmarks_2d.values()), dtype=\"double\")\n",
    "        except: return None, None, None\n",
    "        \n",
    "        h, w = img_shape[:2]\n",
    "        focal = w\n",
    "        center = (w/2, h/2)\n",
    "        K = np.array([[focal,0,center[0]], [0,focal,center[1]], [0,0,1]], dtype=\"double\")\n",
    "        \n",
    "        success, rvec, tvec = cv2.solvePnP(model_points, image_points, K, None)\n",
    "        if not success: return None, None, None\n",
    "        \n",
    "        R, _ = cv2.Rodrigues(rvec)\n",
    "        sy = math.sqrt(R[0,0]**2 + R[1,0]**2)\n",
    "        if sy < 1e-6: return 0, 0, 0\n",
    "        \n",
    "        yaw = math.degrees(math.atan2(-R[2,0], sy))\n",
    "        pitch = math.degrees(math.atan2(R[2,1], R[2,2]))\n",
    "        roll = math.degrees(math.atan2(R[1,0], R[0,0]))\n",
    "        return yaw, pitch, roll\n",
    "\n",
    "    def create_json_alert(self, vtype, severity, conf, evidence):\n",
    "        self.json_alert_id += 1\n",
    "        alert = {\n",
    "            \"session_id\": f\"exam_{int(self.session_start)}\",\n",
    "            \"alert_id\": f\"A{self.json_alert_id:03d}\",\n",
    "            \"timestamp\": datetime.utcnow().isoformat() + 'Z',\n",
    "            \"severity\": severity,\n",
    "            \"violation_type\": vtype,\n",
    "            \"confidence\": conf,\n",
    "            \"suspicion_score\": self.suspicion_score,\n",
    "            \"total_violations\": self.total_violations,  # ğŸ”¥ NEW\n",
    "            \"evidence\": evidence\n",
    "        }\n",
    "        self.alerts_json.append(alert)\n",
    "        return alert\n",
    "\n",
    "    def compute_mouth_aspect_ratio(self, mouth_pts):\n",
    "        top, bottom, left, right = [np.array(v) for v in mouth_pts.values()]\n",
    "        vert = np.linalg.norm(top - bottom)\n",
    "        horiz = np.linalg.norm(left - right)\n",
    "        return vert / horiz if horiz != 0 else 0.0\n",
    "\n",
    "    def run(self):\n",
    "        self.start_audio()\n",
    "        print(\"ğŸ¥ LIVE! q=quit, s=summary\")\n",
    "        print(\"ğŸ“± Test: Any violation 2x=âš ï¸WARNING, 4x=ğŸ”’LOCKOUT (TOTAL COUNT)\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                if self.exam_locked and time.time() - self.lockout_time > 10:\n",
    "                    print(\"ğŸ”’ Exam locked. Restart to continue.\")\n",
    "                    break\n",
    "                    \n",
    "                frame_start = time.time()\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret: break\n",
    "                \n",
    "                frame = cv2.flip(frame, 1)\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = self.face_mesh.process(frame_rgb)\n",
    "                h, w = frame.shape[:2]\n",
    "                \n",
    "                current_time = self.get_current_time()\n",
    "                \n",
    "                # Audio\n",
    "                while not self._audio_queue.empty():\n",
    "                    self._audio_rms_db = self._audio_queue.get_nowait()\n",
    "                \n",
    "                violations = []\n",
    "                \n",
    "                # ğŸ”¥ WARNING OVERLAY FIRST\n",
    "                self.draw_warning_overlay(frame, h, w)\n",
    "                \n",
    "                if self.exam_locked:\n",
    "                    cv2.imshow(\"ğŸš€ Exam Proctor v2.5 - LOCKED\", frame)\n",
    "                    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "                    continue\n",
    "                \n",
    "                # ğŸ”¥ ALL DETECTIONS (with TOTAL violation counting)\n",
    "                if self.detect_mobile_phone(frame, gray):\n",
    "                    self.log_event(\"MobilePhone\", \"0.92\", \"Mobile detected\")\n",
    "                    self.create_json_alert(\"MobilePhone\", \"CRITICAL\", 0.92, {\"type\": \"phone\"})\n",
    "                    self.beep_alert(1000, 300)\n",
    "                    self.check_total_violations()\n",
    "                \n",
    "                # Occlusion\n",
    "                if np.mean(frame) < 20:\n",
    "                    self.occlusion_count += 1\n",
    "                    if self.occlusion_count > CONFIG[\"occlusion_frames\"]:\n",
    "                        self.log_event(\"WebcamOccluded\", \"1.0\", \"Camera blocked\")\n",
    "                        self.check_total_violations()\n",
    "                else:\n",
    "                    self.occlusion_count = 0\n",
    "                \n",
    "                # Face analysis\n",
    "                if not results.multi_face_landmarks:\n",
    "                    self.log_event(\"NoFace\", \"0\", \"No face\")\n",
    "                    self.check_total_violations()\n",
    "                else:\n",
    "                    faces = results.multi_face_landmarks\n",
    "                    if len(faces) > 1:\n",
    "                        self.log_event(\"MultipleFaces\", str(len(faces)), f\"{len(faces)} faces\")\n",
    "                        self.check_total_violations()\n",
    "                    \n",
    "                    face_lms = faces[0]\n",
    "                    self.mp_draw.draw_landmarks(frame, face_lms, self.mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                                               connection_drawing_spec=self.drawing_spec)\n",
    "                    \n",
    "                    lm_list = face_lms.landmark\n",
    "                    def idx(i): return lm_list[i]\n",
    "                    \n",
    "                    # ğŸ”¥ EYES (smaller dots)\n",
    "                    self.draw_eye_landmarks(frame, lm_list, h, w)\n",
    "                    \n",
    "                    # ğŸ”¥ SHOULDERS\n",
    "                    shoulder_violation, shoulder_move = self.detect_shoulder_movement(lm_list, frame.shape)\n",
    "                    if shoulder_violation:\n",
    "                        self.log_event(\"ShoulderMovement\", f\"{shoulder_move:.0f}px\", \"Shoulder movement\")\n",
    "                        self.check_total_violations()\n",
    "                    \n",
    "                    # Head pose\n",
    "                    landmarks_2d = {\n",
    "                        'nose_tip': (idx(1).x*w, idx(1).y*h),\n",
    "                        'chin': (idx(152).x*w, idx(152).y*h),\n",
    "                        'left_eye': (idx(33).x*w, idx(33).y*h),\n",
    "                        'right_eye': (idx(263).x*w, idx(263).y*h),\n",
    "                        'left_mouth': (idx(61).x*w, idx(61).y*h),\n",
    "                        'right_mouth': (idx(291).x*w, idx(291).y*h)\n",
    "                    }\n",
    "                    yaw, pitch, roll = self.estimate_head_pose(frame.shape, landmarks_2d)\n",
    "                    \n",
    "                    if yaw is not None and abs(yaw) > CONFIG[\"yaw_thresh\"]:\n",
    "                        dir_str = \"LookingLeft\" if yaw < 0 else \"LookingRight\"\n",
    "                        self.log_event(dir_str, f\"{yaw:.1f}\", f\"Head turned\")\n",
    "                        self.check_total_violations()\n",
    "                    \n",
    "                    # Mouth\n",
    "                    mouth_pts = {\n",
    "                        'top': (idx(13).x, idx(13).y),\n",
    "                        'bottom': (idx(14).x, idx(14).y),\n",
    "                        'left': (idx(61).x, idx(61).y),\n",
    "                        'right': (idx(291).x, idx(291).y)\n",
    "                    }\n",
    "                    mar = self.compute_mouth_aspect_ratio(mouth_pts)\n",
    "                    if mar > CONFIG[\"mouth_mar_thresh\"]:\n",
    "                        self.log_event(\"MouthOpen\", f\"{mar:.2f}\", \"Talking\")\n",
    "                        self.check_total_violations()\n",
    "                    \n",
    "                    # Blink\n",
    "                    if len(self.blink_history) >= 60:\n",
    "                        recent_blinks = sum(1 for e in list(self.blink_history)[-60:] if e < CONFIG[\"blink_ear_thresh\"])\n",
    "                        rate = (recent_blinks / 2.0) * 60\n",
    "                        if rate > 40:\n",
    "                            self.log_event(\"ExcessiveBlinking\", f\"{rate:.0f}/min\", \"Suspicious\")\n",
    "                            self.check_total_violations()\n",
    "                \n",
    "                # ğŸ”¥ AUDIO (20dB threshold as requested)\n",
    "                if self._audio_rms_db > CONFIG[\"audio_thresh_db\"]:\n",
    "                    self.log_event(\"AudioDetected\", f\"{self._audio_rms_db:.1f}dB\", \"Voice/Noise >-96dB\")\n",
    "                    self.check_total_violations()\n",
    "                \n",
    "                # Suspicion score\n",
    "                if self.total_violations > 0:\n",
    "                    self.suspicion_score = min(1.0, self.suspicion_score + 0.1)\n",
    "                \n",
    "                # ğŸ”¥ UI - Shows TOTAL violations\n",
    "                color = (0,255,0) if self.total_violations < 2 else (0,165,255) if self.total_violations < 4 else (0,0,255)\n",
    "                status = f\"TOTAL: {self.total_violations}/4 | S:{self.suspicion_score:.2f}\"\n",
    "                \n",
    "                cv2.rectangle(frame, (10,10), (w-10,80), (30,30,30), -1)\n",
    "                cv2.putText(frame, status, (20,35), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "                cv2.putText(frame, f\"Alerts: {len(self.alerts_json)}\", (20,55), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "                \n",
    "                cv2.putText(frame, f\"A:{self._audio_rms_db:.0f}dB\", (w-200,35), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0) if self._audio_rms_db < CONFIG[\"audio_thresh_db\"] else (0,0,255), 2)\n",
    "                \n",
    "                cv2.rectangle(frame, (w-220, h-60), (w-10, h-10), (20,20,20), -1)\n",
    "                cv2.putText(frame, current_time, (w-210, h-25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "                \n",
    "                cv2.imshow(\"ğŸš€ Exam Proctor v2.5 - TOTAL VIOLATION COUNTING\", frame)\n",
    "                \n",
    "                fps = 1.0 / (time.time() - frame_start)\n",
    "                self.fps_history.append(fps)\n",
    "                \n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q') or key == 27: break\n",
    "                if key == ord('s'): self.export_summary()\n",
    "                \n",
    "        finally:\n",
    "            self.cleanup()\n",
    "            self.export_summary()\n",
    "\n",
    "    def export_summary(self):\n",
    "        duration = time.time() - self.session_start\n",
    "        summary = {\n",
    "            \"session_id\": f\"exam_{int(self.session_start)}\",\n",
    "            \"duration_min\": round(duration/60, 1),\n",
    "            \"total_violations\": self.total_violations,  # ğŸ”¥ NEW\n",
    "            \"total_alerts\": len(self.alerts_json),\n",
    "            \"suspicion_score\": self.suspicion_score,\n",
    "            \"exam_locked\": self.exam_locked,\n",
    "            \"violations\": dict(self.violation_history),\n",
    "            \"avg_fps\": sum(self.fps_history)/len(self.fps_history) if self.fps_history else 0,\n",
    "            \"recommendation\": \"PASS\" if self.total_violations < 2 and not self.exam_locked else \"FAIL\"\n",
    "        }\n",
    "        with open(\"session_summary.json\", \"w\") as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        print(\"\\nğŸ“Š SUMMARY SAVED:\")\n",
    "        print(json.dumps(summary, indent=2))\n",
    "\n",
    "    def cleanup(self):\n",
    "        if self.cap: self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        if self._audio_running:\n",
    "            self._audio_stream.stop()\n",
    "            self._audio_stream.close()\n",
    "\n",
    "# ğŸ”¥ RUN!\n",
    "if __name__ == \"__main__\":\n",
    "    proctor = AdvancedExamProctor(cam_idx=0)\n",
    "    proctor.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d98271-06d0-441d-8a56-2b7857572747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb88158-90de-4af6-bcda-ea4ba2c1d9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc73ae-d623-49f1-87f7-9bb00c25225b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
